{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle \n",
    "\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as json_file:\n",
    "    raw_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/j/Desktop/programming/ML/github/object_detection_cv/data/data1/downloaded_data\n",
      "409\n",
      "['63.jpg' '77.jpg' '162.jpg' '88.jpg' '348.jpg' '360.jpg' '406.jpg'\n",
      " '412.jpg' '374.jpg' '228.jpg' '214.jpg' '200.jpg' '215.jpg' '229.jpg'\n",
      " '413.jpg' '375.jpg' '361.jpg' '407.jpg' '349.jpg' '177.jpg' '89.jpg'\n",
      " '163.jpg' '188.jpg' '76.jpg' '62.jpg' '74.jpg' '60.jpg' '48.jpg'\n",
      " '161.jpg' '388.jpg' '411.jpg' '405.jpg' '363.jpg' '217.jpg' '216.jpg'\n",
      " '202.jpg' '564.jpg' '404.jpg' '362.jpg' '376.jpg' '410.jpg' '438.jpg'\n",
      " '389.jpg' '160.jpg' '174.jpg' '148.jpg' '61.jpg' '59.jpg' '71.jpg'\n",
      " '164.jpg' '158.jpg' '399.jpg' '372.jpg' '366.jpg' '400.jpg' '560.jpg'\n",
      " '206.jpg' '212.jpg' '549.jpg' '213.jpg' '429.jpg' '401.jpg' '415.jpg'\n",
      " '373.jpg' '398.jpg' '159.jpg' '165.jpg' '70.jpg' '58.jpg' '8.jpg'\n",
      " '198.jpg' '72.jpg' '167.jpg' '99.jpg' '173.jpg' '403.jpg' '371.jpg'\n",
      " '417.jpg' '359.jpg' '211.jpg' '205.jpg' '563.jpg' '239.jpg' '238.jpg'\n",
      " '204.jpg' '562.jpg' '210.jpg' '358.jpg' '370.jpg' '416.jpg' '364.jpg'\n",
      " '172.jpg' '166.jpg' '98.jpg' '73.jpg' '199.jpg' '14.jpg' '28.jpg'\n",
      " '129.jpg' '101.jpg' '115.jpg' '459.jpg' '317.jpg' '471.jpg' '511.jpg'\n",
      " '277.jpg' '505.jpg' '262.jpg' '510.jpg' '276.jpg' '538.jpg' '289.jpg'\n",
      " '316.jpg' '470.jpg' '464.jpg' '302.jpg' '458.jpg' '100.jpg' '128.jpg'\n",
      " '15.jpg' '17.jpg' '116.jpg' '102.jpg' '328.jpg' '472.jpg' '300.jpg'\n",
      " '506.jpg' '260.jpg' '274.jpg' '513.jpg' '507.jpg' '249.jpg' '301.jpg'\n",
      " '467.jpg' '473.jpg' '315.jpg' '103.jpg' '117.jpg' '16.jpg' '113.jpg'\n",
      " '107.jpg' '488.jpg' '463.jpg' '305.jpg' '339.jpg' '265.jpg' '503.jpg'\n",
      " '517.jpg' '259.jpg' '258.jpg' '516.jpg' '270.jpg' '264.jpg' '502.jpg'\n",
      " '338.jpg' '462.jpg' '310.jpg' '476.jpg' '489.jpg' '112.jpg' '13.jpg'\n",
      " '39.jpg' '11.jpg' '104.jpg' '110.jpg' '138.jpg' '306.jpg' '474.jpg'\n",
      " '312.jpg' '448.jpg' '299.jpg' '514.jpg' '500.jpg' '266.jpg' '501.jpg'\n",
      " '267.jpg' '273.jpg' '515.jpg' '449.jpg' '307.jpg' '461.jpg' '139.jpg'\n",
      " '105.jpg' '10.jpg' '38.jpg' '35.jpg' '108.jpg' '134.jpg' '487.jpg'\n",
      " '493.jpg' '478.jpg' '444.jpg' '322.jpg' '336.jpg' '450.jpg' '295.jpg'\n",
      " '281.jpg' '518.jpg' '530.jpg' '256.jpg' '242.jpg' '524.jpg' '243.jpg'\n",
      " '525.jpg' '531.jpg' '294.jpg' '337.jpg' '451.jpg' '445.jpg' '323.jpg'\n",
      " '479.jpg' '492.jpg' '486.jpg' '135.jpg' '121.jpg' '20.jpg' '36.jpg'\n",
      " '22.jpg' '137.jpg' '123.jpg' '484.jpg' '453.jpg' '321.jpg' '447.jpg'\n",
      " '282.jpg' '296.jpg' '269.jpg' '533.jpg' '254.jpg' '532.jpg' '526.jpg'\n",
      " '240.jpg' '268.jpg' '283.jpg' '320.jpg' '446.jpg' '452.jpg' '334.jpg'\n",
      " '308.jpg' '485.jpg' '122.jpg' '136.jpg' '23.jpg' '37.jpg' '27.jpg'\n",
      " '126.jpg' '495.jpg' '330.jpg' '456.jpg' '442.jpg' '318.jpg' '287.jpg'\n",
      " '244.jpg' '522.jpg' '536.jpg' '250.jpg' '278.jpg' '279.jpg' '537.jpg'\n",
      " '251.jpg' '523.jpg' '286.jpg' '319.jpg' '325.jpg' '331.jpg' '127.jpg'\n",
      " '32.jpg' '18.jpg' '131.jpg' '119.jpg' '482.jpg' '496.jpg' '327.jpg'\n",
      " '441.jpg' '455.jpg' '469.jpg' '284.jpg' '253.jpg' '521.jpg' '247.jpg'\n",
      " '520.jpg' '534.jpg' '285.jpg' '468.jpg' '454.jpg' '440.jpg' '497.jpg'\n",
      " '483.jpg' '118.jpg' '130.jpg' '124.jpg' '25.jpg' '19.jpg' '4.jpg'\n",
      " '194.jpg' '95.jpg' '143.jpg' '157.jpg' '382.jpg' '396.jpg' '369.jpg'\n",
      " '433.jpg' '355.jpg' '547.jpg' '221.jpg' '546.jpg' '220.jpg' '234.jpg'\n",
      " '552.jpg' '208.jpg' '432.jpg' '426.jpg' '368.jpg' '397.jpg' '383.jpg'\n",
      " '156.jpg' '94.jpg' '80.jpg' '5.jpg' '43.jpg' '55.jpg' '7.jpg' '69.jpg'\n",
      " '168.jpg' '82.jpg' '154.jpg' '140.jpg' '395.jpg' '381.jpg' '418.jpg'\n",
      " '356.jpg' '430.jpg' '342.jpg' '222.jpg' '550.jpg' '236.jpg' '551.jpg'\n",
      " '237.jpg' '545.jpg' '425.jpg' '343.jpg' '357.jpg' '431.jpg' '419.jpg'\n",
      " '141.jpg' '155.jpg' '83.jpg' '97.jpg' '182.jpg' '68.jpg' '196.jpg'\n",
      " '54.jpg' '6.jpg' '192.jpg' '186.jpg' '2.jpg' '50.jpg' '44.jpg' '151.jpg'\n",
      " '145.jpg' '93.jpg' '87.jpg' '179.jpg' '390.jpg' '384.jpg' '347.jpg'\n",
      " '409.jpg' '227.jpg' '233.jpg' '232.jpg' '554.jpg' '540.jpg' '226.jpg'\n",
      " '346.jpg' '420.jpg' '352.jpg' '385.jpg' '92.jpg' '144.jpg' '45.jpg'\n",
      " '3.jpg' '51.jpg' '79.jpg' '187.jpg' '193.jpg' '185.jpg' '191.jpg'\n",
      " '47.jpg' '1.jpg' '146.jpg' '152.jpg' '84.jpg' '387.jpg' '393.jpg'\n",
      " '344.jpg' '350.jpg' '378.jpg' '230.jpg' '542.jpg' '218.jpg' '225.jpg'\n",
      " '557.jpg' '351.jpg' '437.jpg' '423.jpg' '345.jpg' '91.jpg' '190.jpg'\n",
      " '184.jpg']\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "data_dir = pathlib.Path(\"/Users/j/Desktop/programming/ML/github/object_detection_cv/data/data1/downloaded_data\")\n",
    "print(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*.jpg')))\n",
    "print(image_count)\n",
    "\n",
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \".DS_Store\"])\n",
    "print(CLASS_NAMES)\n",
    "\n",
    "\n",
    "# The 1./255 is to convert from uint8 to float32 in range [0,1]. Better for d\\feeding to a neural net\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "#  Batch Sixe is how many images are we feeding in on one batch. It can be set to none. It is important to set it\n",
    "# to optimise computing power\n",
    "IMG_HEIGHT = 50\n",
    "IMG_WIDTH = 50\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "\n",
    "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='sparse')\n",
    "#  here class_mode='sparse' is imp because we want a list of 1-d numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
