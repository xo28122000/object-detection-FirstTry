{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle \n",
    "\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as json_file:\n",
    "    raw_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/j/Desktop/programming/ML/github/object_detection_cv/data/data1/downloaded_data\n",
      "409\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "data_dir = pathlib.Path(\"/Users/j/Desktop/programming/ML/github/object_detection_cv/data/data1/downloaded_data\")\n",
    "print(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*.jpg')))\n",
    "print(image_count)\n",
    "\n",
    "\n",
    "\n",
    "# The 1./255 is to convert from uint8 to float32 in range [0,1]. Better for d\\feeding to a neural net\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "#  Batch Sixe is how many images are we feeding in on one batch. It can be set to none. It is important to set it\n",
    "# to optimise computing power\n",
    "IMG_HEIGHT = 50\n",
    "IMG_WIDTH = 50\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "\n",
    "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode=None)\n",
    "#  here class_mode='sparse' is imp because we want a list of 1-d numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8595541ad4f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "train_data_gen.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from time import time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 409 images\n"
     ]
    }
   ],
   "source": [
    "folder = \"/Users/j/Desktop/programming/ML/github/object_detection_cv/data/data1/downloaded_data\"\n",
    "\n",
    "onlyfiles = [f for f in os.listdir(folder) if (os.path.isfile(os.path.join(folder, f)) and f!= \".DS_Store\")]\n",
    "\n",
    "print(\"Working with {0} images\".format(len(onlyfiles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Dimensions\n",
    "image_width = 32\n",
    "image_height = 32\n",
    "\n",
    "channels = 3\n",
    "nb_classes = 1\n",
    "\n",
    "dataset = np.ndarray(shape=(len(train_files),  image_height, image_width,channels),\n",
    "                     dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "for _file in onlyfiles:\n",
    "    img = load_img(folder + \"/\" + _file)  # this is a PIL image\n",
    "    img.thumbnail((image_width, image_height))\n",
    "    # Convert to Numpy Array\n",
    "    x = img_to_array(img)  \n",
    "    x = x.reshape((3, 120, 160))\n",
    "    # Normalize\n",
    "    x = (x - 128.0) / 128.0\n",
    "    dataset[i] = x\n",
    "    i += 1\n",
    "    if i % 250 == 0:\n",
    "        print(\"%d images to array\" % i)\n",
    "print(\"All images to array!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
